{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments: Sensitive Analysis Hyperparameter RSAST:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is runned RSAST in a set of UCR datasets with a predefined number of runs (\"runs\"). Then, it is selected a range (\"range_total\") between 1, 10, 30 ,50 and 100 for the selected dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os \n",
    "#add sast library path\n",
    "file_path = os.path.dirname(os.getcwd())+\"/sast\"\n",
    "\n",
    "#file_path = r\"C:\\Users\\Public\\random_sast\\sast\"\n",
    "sys.path.append(file_path)\n",
    "\n",
    "file_path = os.path.dirname(os.getcwd())+\"\\sast\"\n",
    "\n",
    "\n",
    "#file_path = r\"C:\\Users\\Public\\random_sast\\sast\"\n",
    "sys.path.append(file_path)\n",
    "\n",
    "file_path = os.getcwd()+\"/sast\"\n",
    "\n",
    "\n",
    "#file_path = r\"C:\\Users\\Public\\random_sast\\sast\"\n",
    "sys.path.append(file_path)\n",
    "\n",
    "file_path = os.getcwd()+\"\\sast\"\n",
    "\n",
    "\n",
    "#file_path = r\"C:\\Users\\Public\\random_sast\\sast\"\n",
    "sys.path.append(file_path)\n",
    "\n",
    "#add cd_diagram library path\n",
    "file_path = os.path.dirname(os.getcwd())+\"\\cd_diagram\"\n",
    "\n",
    "#file_path = r\"C:\\Users\\Public\\random_sast\\cd_diagram\"\n",
    "sys.path.append(file_path)\n",
    "\n",
    "\n",
    "file_path = os.path.dirname(os.getcwd())+\"/cd_diagram\"\n",
    "#file_path = r\"C:\\Users\\Public\\random_sast\\sast\"\n",
    "sys.path.append(file_path)\n",
    "\n",
    "file_path = os.getcwd()+\"\\cd_diagram\"\n",
    "#file_path = r\"C:\\Users\\Public\\random_sast\\sast\"\n",
    "sys.path.append(file_path)\n",
    "\n",
    "file_path = os.getcwd()+\"/cd_diagram\"\n",
    "#file_path = r\"C:\\Users\\Public\\random_sast\\sast\"\n",
    "sys.path.append(file_path)\n",
    "\n",
    "sys.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sast import *\n",
    "import pandas as pd\n",
    "import researchpy\n",
    "import math\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set directory where the csv files are located\n",
    "directory = os.getcwd()+'/ResultsByClassifier'\n",
    "\n",
    "# Create an empty list to store the dataframes\n",
    "dfs = []\n",
    "\n",
    "header=['dataset']\n",
    "res = [str(ele) for ele in range(30)]\n",
    "header.extend(res)\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    # Check if the file starts with \"df_overall_tunning\" and ends with \".csv\"\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Read the csv file into a dataframe\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(filepath, names=header,index_col=False)\n",
    "\n",
    "        # Append the dataframe to the list\n",
    "        df['filename']=filename\n",
    "        dfs.append(df)\n",
    "\n",
    "\n",
    "# Concatenate all the dataframes in the list into one dataframe\n",
    "df_other_methods = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "res=res[:10]\n",
    "\n",
    "df_other_methods[\"avg\"]=df_other_methods[res].mean(axis=1)\n",
    "\n",
    "df_other_methods=df_other_methods[['filename','dataset','avg']]\n",
    "df_other_methods['method']=df_other_methods['filename'].str.split('.').str[0]+\"_UCR_RES_10\"\n",
    "df_other_methods\n",
    "df_other_methods=df_other_methods.rename(columns={'avg':'score'})\n",
    "df_other_methods=df_other_methods[['dataset','score','method']]\n",
    "\n",
    "df_other_methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_other_methods['method'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory where the csv files are located\n",
    "\n",
    "directories=[]\n",
    "default_split_acf_pacf_p_10_30_k_1_10_sast=True\n",
    "default_split_acf_pacf_p_10_30_k_1_10_notsast=True\n",
    "default_split_all_p_10_30_k_1_10=True\n",
    "default_split_all_acfandpacf_p_10_30_k_30_50=True\n",
    "resampling_acf_pacf_p_10_30_k_1_10_sast=True\n",
    "\n",
    "if default_split_acf_pacf_p_10_30_k_1_10_sast:\n",
    "    directories.append(os.getcwd()+'/ResultsRsast/Server17_Comparison_RSAST')\n",
    "if default_split_acf_pacf_p_10_30_k_1_10_notsast:\n",
    "    directories.append(os.getcwd()+'/ResultsRsast/Server17_not_used_sast')\n",
    "if default_split_all_p_10_30_k_1_10:\n",
    "    directories.append(os.getcwd()+'/ResultsRsast/Server17_Comparison_RSAST_All')   \n",
    "if default_split_all_acfandpacf_p_10_30_k_30_50:\n",
    "    directories.append(os.getcwd()+'/ResultsRsast/Server17_Comparison_RSAST_Extra_1')    \n",
    "if default_maxpacf_none_p_10_30_k_30_50:\n",
    "    directories.append(os.getcwd()+'/ResultsRsast/Server17_Comparison_RSAST_Extra_2')    \n",
    "if default_split_acf_pacf_p_10_30_k_1_10_sast:\n",
    "    directories.append(os.getcwd()+'/ResultsRsast/Server17_Resampling_Comparison_RSAST')     \n",
    "\n",
    "    #directories.append(os.getcwd()+'/ResultsRsast/Server17_Resampling_Comparison_RSAST')\n",
    "\n",
    "    #directories.append(os.getcwd()+'/ResultsRsast/Server16_Hyperparameter_Tunning')\n",
    "    #directories.append(os.getcwd()+'/ResultsRsast/Server17_Hyperparameter_Tunning')\n",
    "    #directories.append(os.getcwd()+'/results_accuracy_per_ds')\n",
    "    #directories.append(os.getcwd()+'/results_accuracy_per_ds_10000')\n",
    "\n",
    "\n",
    "# Create an empty list to store the dataframes\n",
    "dfs = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for directory in directories:\n",
    "    for filename in os.listdir(directory):\n",
    "        # Check if the file starts with \"df_overall_tunning\" and ends with \".csv\"\n",
    "        if filename.startswith(\"df_all_overall_tunning\") and filename.endswith(\".csv\"):\n",
    "            # Read the csv file into a dataframe\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(filepath)\n",
    "            df['rpoint']=df['rpoint'].astype(str)\n",
    "            df['nb_per_class']=df['nb_per_class'].astype(str)\n",
    "            df['rpoint']=df['rpoint'].replace(\"(lenthg ts)//2\",\"half_len\")\n",
    "            df['nb_per_class']=df['nb_per_class'].replace(\"(max instances per class)//2\",\"half_instance\")\n",
    "            df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
    "            df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
    "            df['directory']=directory\n",
    "            # Append the dataframe to the list\n",
    "            dfs.append(df)\n",
    "\n",
    "# Concatenate all the dataframes in the list into one dataframe\n",
    "df_result = pd.concat(dfs, ignore_index=True)\n",
    "# df_result.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total DS:\" + str(len(df_result['dataset_name'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_all=pd.pivot_table(df_result,index='dataset_name',values='accuracy',aggfunc=\"count\")\n",
    "ds_complete=pv_all[pv_all.accuracy==max(pv_all.accuracy)].reset_index().dataset_name.unique()\n",
    "ds_complete\n",
    "df_result=df_result[df_result.dataset_name.isin(ds_complete)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_all=pd.pivot_table(df_result,index='len_method',values='accuracy',aggfunc=\"count\")\n",
    "pv_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_all=pd.pivot_table(df_result,index='len_method',values='accuracy',aggfunc=\"count\")\n",
    "len_complete=pv_all[pv_all.accuracy==max(pv_all.accuracy)].reset_index().len_method.unique()\n",
    "len_complete\n",
    "df_result=df_result[df_result.len_method.isin(len_complete)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result=df_result[df_result.nb_per_class.isin(['1', '10'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get ds tested overall\n",
    "print(\"Total DS:\" + str(len(df_result['dataset_name'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get ds tested overall\n",
    "pd.pivot_table(df_result, index=\"dataset_name\", values=\"accuracy\", aggfunc=\"count\").reset_index()[\"dataset_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get ds tested overall\n",
    "print(\"Total Param Combination:\" + str(len(df_result['classifier_name'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get len methods of generated datasets\n",
    "df_result.classifier_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get columns of generated datasets\n",
    "df_result.columns.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_result.dataset_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_used_sast=pd.read_excel(\"DataSetsUCLASummary.xlsx\", dtype=str)\n",
    "df_used_sast.columns\n",
    "ds_bake=df_used_sast[df_used_sast['BAKE OFF']=='Y'].Name.unique()\n",
    "len(ds_bake)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(df_result[df_result.dataset_name.isin(ds_bake)].dataset_name.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_print=pd.pivot_table(df_result, index=\"dataset_name\", values=\"accuracy\", columns=\"classifier_name\").reset_index().round(2)\n",
    "\"\"\"\n",
    "df_print=df_print[['dataset_name','ACF&PACF: n_random_points=10 nb_inst_per_class=1',\n",
    "       'ACF&PACF: n_random_points=10 nb_inst_per_class=10',\n",
    "       'ACF&PACF: n_random_points=30 nb_inst_per_class=1',\n",
    "       'ACF&PACF: n_random_points=30 nb_inst_per_class=10']]\n",
    "\"\"\"\n",
    "df_print.to_csv(\"results_default_split.csv\")\n",
    "df_print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df_tunned_rsast=df_used_sast.merge(pd.pivot_table(df_result, index=\"dataset_name\", values=\"accuracy\", columns=\"classifier_name\").reset_index(),how='right',right_on=\"dataset_name\",left_on=\"Name\").round(2)[['Name', 'ACF&PACF: n_random_points=30 nb_inst_per_class=10','ACF&PACF: n_random_points=30 nb_inst_per_class=10','ACF&PACF: n_random_points=30 nb_inst_per_class=1','Type', 'Train ', 'Test ', 'Class', 'Length']]\n",
    "df_tunned_rsast.sort_values(\"Name\",inplace=True)\n",
    "df_tunned_rsast.to_excel('ds_runned_rsast.xlsx')\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tunning RSAST "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy: Subsequence Lenght Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_param=df_result\n",
    "\n",
    "#filter_param=filter_param[filter_param.len_method=='ACF&PACF']\n",
    "filter_param.dataset_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_param.rpoint.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_param=filter_param[filter_param.rpoint.isin(['1', '10', '30'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_param.nb_per_class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_param=filter_param[filter_param.nb_per_class.isin(['1', '10', '30'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pivot table with the mean of score by dataset\n",
    "len_method_vs_ds=pd.pivot_table(filter_param, values='accuracy', index=['len_method'],columns=['dataset_name'], aggfunc='mean')\n",
    "len_method_vs_ds=np.transpose(len_method_vs_ds)#[['ACF','PACF']]\n",
    "len_method_vs_ds=len_method_vs_ds.reset_index()\n",
    "df_rocket=df_other_methods[df_other_methods[\"method\"]==\"SAST\"]\n",
    "merged_df = len_method_vs_ds.merge(df_rocket,left_on='dataset_name', right_on='dataset',  how='left')\n",
    "merged_df=merged_df.drop('dataset',axis=1)\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Summary statistics for a Series (single variable)\n",
    "\n",
    "summ_ds=filter_param\n",
    "summ_ds=researchpy.summary_cont(summ_ds.groupby(['dataset_name'])['accuracy'], conf = 0.95)\n",
    "summ_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = filter_param.groupby(['len_method'])['accuracy'].agg(['mean', 'count', 'std'])\n",
    "\n",
    "ci95_hi = []\n",
    "ci95_lo = []\n",
    "\n",
    "for i in stats.index:\n",
    "    m, c, s = stats.loc[i]\n",
    "    ci95_hi.append(m + 1.96*s/math.sqrt(c))\n",
    "    ci95_lo.append(m - 1.96*s/math.sqrt(c))\n",
    "\n",
    "stats['ci95_hi'] = ci95_hi\n",
    "stats['ci95_lo'] = ci95_lo\n",
    "print(stats.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Boxplot Tunning Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.nb_per_class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.len_method.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate hyperparameter tuning boxplots\n",
    "\n",
    "for k, ints in enumerate(df_result.nb_per_class.unique()):\n",
    "\n",
    "    for len_m in df_result.len_method.unique():\n",
    "        print(\"nb_per_class: \"+str(ints))\n",
    "        print(\"len_m: \"+str(len_m))\n",
    "        df_to_cd=df_result[df_result.classifier_name.str.contains(r'^'+len_m+':.*nb_inst_per_class='+str(ints)+'$')]\n",
    "        #df_to_cd=pd.pivot_table(df_to_cd, index=['dataset_name','classifier_name'], columns=['rpoint'],values='accuracy')\n",
    "        #df_to_cd = df_to_cd.reindex(columns=[\"1\",\"10\",\"30\",\"50\",\"100\",\"half_len\"])\n",
    "        \n",
    "        #print(df_to_cd.head(5))\n",
    "\n",
    "        # Plot\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "        \n",
    "        #order=list(df_to_cd)\n",
    "        sns.boxplot(data=df_to_cd, x='rpoint', y='accuracy', palette=\"Blues\")\n",
    "        #plt.boxplot(df_to_cd, labels=list(df_to_cd), showfliers=False)\n",
    "        \n",
    "        max_bx=max(df_to_cd.accuracy)\n",
    "        min_bx=min(df_to_cd.accuracy)\n",
    "        \n",
    "        ax.set_ylim(min_bx,max_bx)\n",
    "        # Axis details\n",
    "        ax.set(xlabel='number of random points', ylabel='accuracy', title='Accuracy Boxplot for Len method:'+len_m+' and N° of Instances:'+ints)\n",
    "        #plt.xticks([1, 2, 3, 4, 5, 6],list(df_to_cd) )\n",
    "        #print(df_to_cd.describe())\n",
    "\n",
    "        # save plot\n",
    "        plt.savefig('images_boxplot_acc/boxplot_acc'+len_m+ints+'.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.classifier_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate hyperparameter tuning boxplots\n",
    "for ds in df_result.dataset_name.unique():\n",
    "    for k, ints in enumerate(df_result.nb_per_class.unique()):\n",
    "        for len_m in df_result.len_method.unique():\n",
    "            print(\"ds:\"+ds)\n",
    "            print(\"nb_per_class:\"+str(ints))\n",
    "            print(\"len_m:\"+len_m)\n",
    "\n",
    "            df_to_cd=df_result[df_result.classifier_name.str.contains(r'^'+len_m+':')]\n",
    "            df_to_cd=df_to_cd[df_to_cd.dataset_name==ds]\n",
    "\n",
    "            df_to_cd[\"time\"]=df_to_cd['cweights_time']+df_to_cd['fsubsequence_time']+df_to_cd['tdataset_time']\n",
    "            df_to_cd[\"time\"]=df_to_cd[\"time\"]/60\n",
    "            max_bx=max(df_to_cd.accuracy)\n",
    "            min_bx=min(df_to_cd.accuracy)\n",
    "            \n",
    "            df_to_cd=df_to_cd[df_to_cd.classifier_name.str.contains(r':.*nb_inst_per_class='+str(ints)+'$')]    \n",
    "\n",
    "            #df_to_cd=pd.pivot_table(df_to_cd, index=['dataset_name','classifier_name'], columns=['rpoint'],values='accuracy')\n",
    "            #df_to_cd = df_to_cd.reindex(columns=[\"1\",\"10\",\"30\",\"50\",\"100\",\"half_len\"])\n",
    "            \n",
    "            #print(df_to_cd.head(5))\n",
    "\n",
    "            # Plot\n",
    "            fig, ax = plt.subplots()\n",
    "            \n",
    "            \n",
    "            #order=list(df_to_cd)\n",
    "            sns.boxplot(data=df_to_cd, x='rpoint', y='accuracy', palette=\"Blues\")\n",
    "            #plt.boxplot(df_to_cd, labels=list(df_to_cd), showfliers=False)\n",
    "            \n",
    "            ax.set_ylim(min_bx,max_bx)\n",
    "            # Axis details\n",
    "            ax.set(xlabel='number of random points', ylabel='accuracy', title='Accuracy Boxplot for Len method:'+len_m+' and N° of Instances:'+ints)\n",
    "            #plt.xticks([1, 2, 3, 4, 5, 6],list(df_to_cd) )\n",
    "            #print(df_to_cd.describe())\n",
    "\n",
    "            # save plot\n",
    "            plt.savefig('images_boxplot_acc_per_ds/boxplot_acc'+len_m+ints+'_'+ds+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate hyperparameter tuning boxplots\n",
    "\n",
    "for k, ints in enumerate(df_result.nb_per_class.unique()):\n",
    "    for len_m in df_result.len_method.unique():\n",
    "        \n",
    "        \n",
    "        df_to_cd=df_result[df_result.classifier_name.str.contains(r'^'+len_m+':.*nb_inst_per_class='+str(ints)+'$')]\n",
    "        df_to_cd[\"time\"]=df_to_cd['cweights_time']+df_to_cd['fsubsequence_time']+df_to_cd['tdataset_time']\n",
    "        df_to_cd[\"time\"]=df_to_cd[\"time\"]/60\n",
    "        #df_to_cd=pd.pivot_table(df_to_cd, index=['dataset_name','classifier_name'], columns=['rpoint'],values='accuracy')\n",
    "        #df_to_cd = df_to_cd.reindex(columns=[\"1\",\"10\",\"30\",\"50\",\"100\",\"half_len\"])\n",
    "        \n",
    "        #print(df_to_cd.head(5))\n",
    "\n",
    "        # Plot\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "        \n",
    "        #order=list(df_to_cd)\n",
    "        sns.boxplot(data=df_to_cd, x='rpoint', y='time', palette=\"Blues\")\n",
    "        #plt.boxplot(df_to_cd, labels=list(df_to_cd), showfliers=False)\n",
    "        \n",
    "        max_bx=max(df_to_cd.time)\n",
    "        min_bx=min(df_to_cd.time)\n",
    "        ax.set_ylim(min_bx,max_bx)\n",
    "        # Axis details\n",
    "        ax.set(xlabel='number of random points', ylabel='time', title='Time Boxplot for Len method:'+len_m+' and N° of Instances:'+ints)\n",
    "        #plt.xticks([1, 2, 3, 4, 5, 6],list(df_to_cd) )\n",
    "        #print(df_to_cd.describe())\n",
    "\n",
    "        # save plot\n",
    "        plt.savefig('images_boxplot_time/boxplot_time'+len_m+ints+'.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate hyperparameter tuning boxplots\n",
    "for ds in df_result.dataset_name.unique():\n",
    "    for k, ints in enumerate(df_result.nb_per_class.unique()):\n",
    "        for len_m in df_result.len_method.unique():\n",
    "        \n",
    "\n",
    "\n",
    "            df_to_cd=df_result[df_result.classifier_name.str.contains(r'^'+len_m+':')]\n",
    "            df_to_cd=df_to_cd[df_to_cd.dataset_name==ds]\n",
    "\n",
    "            df_to_cd[\"time\"]=df_to_cd['cweights_time']+df_to_cd['fsubsequence_time']+df_to_cd['tdataset_time']\n",
    "            df_to_cd[\"time\"]=df_to_cd[\"time\"]/60\n",
    "            max_bx=max(df_to_cd.time)\n",
    "            min_bx=min(df_to_cd.time)\n",
    "\n",
    "            df_to_cd=df_to_cd[df_to_cd.classifier_name.str.contains(r':.*nb_inst_per_class='+str(ints)+'$')]\n",
    "\n",
    "\n",
    "            #df_to_cd=pd.pivot_table(df_to_cd, index=['dataset_name','classifier_name'], columns=['rpoint'],values='accuracy')\n",
    "            #df_to_cd = df_to_cd.reindex(columns=[\"1\",\"10\",\"30\",\"50\",\"100\",\"half_len\"])\n",
    "            \n",
    "            #print(df_to_cd.head(5))\n",
    "\n",
    "            # Plot\n",
    "            fig, ax = plt.subplots()\n",
    "            \n",
    "            \n",
    "            #order=list(df_to_cd)\n",
    "            sns.boxplot(data=df_to_cd, x='rpoint', y='time', palette=\"Blues\")\n",
    "            #plt.boxplot(df_to_cd, labels=list(df_to_cd), showfliers=False)\n",
    "            \n",
    "\n",
    "            ax.set_ylim(min_bx,max_bx)\n",
    "            # Axis details\n",
    "            ax.set(xlabel='number of random points', ylabel='time', title='Time Boxplot for Len method:'+len_m+' and N° of Instances:'+ints)\n",
    "            #plt.xticks([1, 2, 3, 4, 5, 6],list(df_to_cd) )\n",
    "            #print(df_to_cd.describe())\n",
    "\n",
    "            # save plot\n",
    "            plt.savefig('images_boxplot_time_per_ds/boxplot_time'+len_m+ints+'_'+ds+'.png')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate CD Diagram Tunning Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf=pd.pivot_table(df_result, values='accuracy', index=['classifier_name','dataset_name','len_method'], aggfunc='mean')\n",
    "df_perf=df_perf.reset_index()\n",
    "df_perf.classifier_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_perf[df_perf.classifier_name.str.contains(r'^'+len_m+':.*$')].classifier_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from cd_function import *\n",
    "#generate hyperparameter tuning cd diagrams\n",
    "\n",
    "best_comb_by_method=[]\n",
    "best=\"\"\n",
    "for len_m in df_perf.len_method.unique():\n",
    "   df_to_cd=df_perf[df_perf.classifier_name.str.contains(r'^'+len_m+':.*$')]\n",
    "   draw_cd_diagram(df_to_cd, labels=True, title=len_m +\" comparison\", fname='images_cd_diagram/cd-diagram_'+len_m+'.png')\n",
    "   _, average_ranks, _ = wilcoxon_holm(df_perf=df_to_cd)\n",
    "   min_rank= min(average_ranks)\n",
    "   average_ranks=pd.DataFrame(average_ranks)\n",
    "   best=average_ranks[average_ranks[0]==min_rank][0].index\n",
    "   best_comb_by_method.append(best[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_comb_by_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf=pd.pivot_table(df_result, values='accuracy', index=['classifier_name','dataset_name','len_method'], aggfunc='mean')\n",
    "df_perf=df_perf.reset_index()\n",
    "df_to_cd=df_perf[df_perf.classifier_name.isin(best_comb_by_method)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_cd_diagram(df_to_cd, labels=True, title=\"Best combination comparison\", fname='images_cd_diagram/cd-diagram_best_com.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf_all=df_perf[['dataset_name','len_method','accuracy']]\n",
    "df_perf_all.rename(columns = {'len_method':'classifier_name'}, inplace = True)\n",
    "df_perf_all=pd.pivot_table(df_perf_all, index=[\"dataset_name\",\"classifier_name\"]).reset_index()\n",
    "df_perf_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_cd_diagram(df_perf_all, labels=True, fname='images_cd_diagram/cd-diagram_all_methods.png')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Focus on most accurate lenght method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overall Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# highest accurate hyperparameters\n",
    "best_comb_by_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by method with ACF&PACF\n",
    "# create a pivot table with the mean of score by hyperparameter\n",
    "df_result_acc=df_result\n",
    "#df_result_acc=df_result_acc[df_result_acc[\"dataset_name\"]==\"Fungi\"]\n",
    "\n",
    "pivot = pd.pivot_table(df_result_acc, values='accuracy', index=['rpoint'],columns=['nb_per_class'], aggfunc='mean')\n",
    "pivot = pivot.reindex(columns=[\"half_instance\",\"1\",\"10\",\"30\",\"50\",\"100\",\"1000\",\"10000\"], index=[\"half_len\",\"1\",\"10\",\"30\",\"50\",\"100\",\"1000\",\"10000\"])\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pivot table with the variatioon of score by hyperparameter\n",
    "pivot = pd.pivot_table(df_result_acc, values='accuracy', index=['rpoint'],columns=['nb_per_class'], aggfunc='var')\n",
    "pivot = pivot.reindex(columns=[\"half_instance\",\"1\",\"10\",\"30\",\"50\",\"100\",\"1000\",\"10000\"], index=[\"half_len\",\"1\",\"10\",\"30\",\"50\",\"100\",\"1000\",\"10000\"])\n",
    "pivot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overall time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_acc.time.sum()/(60*60*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pivot table with the mean of time spent in minutes\n",
    "pivot=pd.pivot_table(df_result_acc, values=['time','cweights_time','fsubsequence_time','tdataset_time','tclassifier_time'], index=['dataset_name'], aggfunc='sum')/60\n",
    "pivot = pivot.reindex(columns=['cweights_time','fsubsequence_time','tdataset_time','tclassifier_time','time'])\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pivot table with the mean of time spent in minutes by random points and instances per class\n",
    "pivot = pd.pivot_table(df_result_acc, values='time', index=['rpoint'],columns=['nb_per_class'], aggfunc='mean')/60\n",
    "pivot = pivot.reindex(columns=[\"half_instance\",\"1\",\"10\",\"30\",\"50\",\"100\",\"1000\",\"10000\"], index=[\"half_len\",\"1\",\"10\",\"30\",\"50\",\"100\",\"1000\",\"10000\"])\n",
    "pivot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate weights time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df_result_acc, values='cweights_time', index=['rpoint'],columns=['nb_per_class'], aggfunc='mean')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finding subsequences time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df_result_acc, values='fsubsequence_time', index=['rpoint'],columns=['nb_per_class'], aggfunc='mean')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform Dataset time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df_result_acc, values='tdataset_time', index=['rpoint'],columns=['nb_per_class'], aggfunc='mean')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df_result_acc, values='tclassifier_time', index=['rpoint'],columns=['nb_per_class'], aggfunc='mean')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsast_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "15558ed87e778df9776c3e85b8e1a3f1f5adbf230fcca0229423f99909b60d27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
