{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments: Sensitive Analysis Hyperparameter RSAST:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is runned RSAST in a set of UCR datasets with a predefined number of runs (\"runs\"). Then, it is selected a range (\"range_total\") between 1, 10, 30 ,50 and 100 for the selected dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nirojasvar/random_sast/ExperimentationRSAST',\n",
       " '/home/nirojasvar/anaconda3/envs/rsast_env/lib/python310.zip',\n",
       " '/home/nirojasvar/anaconda3/envs/rsast_env/lib/python3.10',\n",
       " '/home/nirojasvar/anaconda3/envs/rsast_env/lib/python3.10/lib-dynload',\n",
       " '',\n",
       " '/home/nirojasvar/anaconda3/envs/rsast_env/lib/python3.10/site-packages',\n",
       " '/home/nirojasvar/random_sast/sast',\n",
       " '/home/nirojasvar/random_sast\\\\sast',\n",
       " '/home/nirojasvar/random_sast/ExperimentationRSAST/sast',\n",
       " '/home/nirojasvar/random_sast/ExperimentationRSAST\\\\sast',\n",
       " '/home/nirojasvar/random_sast\\\\cd_diagram',\n",
       " '/home/nirojasvar/random_sast/cd_diagram',\n",
       " '/home/nirojasvar/random_sast/ExperimentationRSAST\\\\cd_diagram',\n",
       " '/home/nirojasvar/random_sast/ExperimentationRSAST/cd_diagram']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "import os \n",
    "#add sast library path\n",
    "file_path = os.path.dirname(os.getcwd())+\"/sast\"\n",
    "\n",
    "#file_path = r\"C:\\Users\\Public\\random_sast\\sast\"\n",
    "sys.path.append(file_path)\n",
    "\n",
    "file_path = os.path.dirname(os.getcwd())+\"\\sast\"\n",
    "\n",
    "\n",
    "#file_path = r\"C:\\Users\\Public\\random_sast\\sast\"\n",
    "sys.path.append(file_path)\n",
    "\n",
    "file_path = os.getcwd()+\"/sast\"\n",
    "\n",
    "\n",
    "#file_path = r\"C:\\Users\\Public\\random_sast\\sast\"\n",
    "sys.path.append(file_path)\n",
    "\n",
    "file_path = os.getcwd()+\"\\sast\"\n",
    "\n",
    "\n",
    "#file_path = r\"C:\\Users\\Public\\random_sast\\sast\"\n",
    "sys.path.append(file_path)\n",
    "\n",
    "#add cd_diagram library path\n",
    "file_path = os.path.dirname(os.getcwd())+\"\\cd_diagram\"\n",
    "\n",
    "#file_path = r\"C:\\Users\\Public\\random_sast\\cd_diagram\"\n",
    "sys.path.append(file_path)\n",
    "\n",
    "\n",
    "file_path = os.path.dirname(os.getcwd())+\"/cd_diagram\"\n",
    "#file_path = r\"C:\\Users\\Public\\random_sast\\sast\"\n",
    "sys.path.append(file_path)\n",
    "\n",
    "file_path = os.getcwd()+\"\\cd_diagram\"\n",
    "#file_path = r\"C:\\Users\\Public\\random_sast\\sast\"\n",
    "sys.path.append(file_path)\n",
    "\n",
    "file_path = os.getcwd()+\"/cd_diagram\"\n",
    "#file_path = r\"C:\\Users\\Public\\random_sast\\sast\"\n",
    "sys.path.append(file_path)\n",
    "\n",
    "sys.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nirojasvar/anaconda3/envs/rsast_env/lib/python3.10/site-packages/mass_ts/_mass_ts.py:17: UserWarning: GPU support will not work. You must pip install mass-ts[gpu].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sast import *\n",
    "import pandas as pd\n",
    "import researchpy\n",
    "import math\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory where the csv files are located\n",
    "directory = os.getcwd()+'/ResultsByClassifier'\n",
    "\n",
    "# Create an empty list to store the dataframes\n",
    "dfs = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    # Check if the file starts with \"df_overall_tunning\" and ends with \".csv\"\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Read the csv file into a dataframe\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        # Append the dataframe to the list\n",
    "        df['filename']=filename\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all the dataframes in the list into one dataframe\n",
    "df_other_methods = pd.concat(dfs, ignore_index=True)\n",
    "df_other_methods=df_other_methods[['filename','folds:','0']]\n",
    "df_other_methods['method']=df_other_methods['filename'].str.split('_').str[0]\n",
    "df_other_methods\n",
    "df_other_methods=df_other_methods.rename(columns={'folds:':'dataset','0':'score'})\n",
    "df_other_methods=df_other_methods[['dataset','score','method']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ROCKET', 'HIVE-COTEv1', 'BOSS', 'RISE', 'SAST', 'TSF',\n",
       "       'InceptionTime', 'TS-CHIEF', 'S-BOSS', 'STC', 'ResNet',\n",
       "       'ProximityForest', 'WEASEL', 'Catch22', 'cBOSS'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_other_methods['method'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
      "/tmp/ipykernel_6569/1017712830.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
      "/tmp/ipykernel_6569/1017712830.py:30: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n"
     ]
    }
   ],
   "source": [
    "# Set directory where the csv files are located\n",
    "#directory = os.getcwd()+'/ResultsRsast'\n",
    "#directory = os.getcwd()+'/results_accuracy_per_ds'\n",
    "\n",
    "directories=[]\n",
    "#directories.append(os.getcwd()+'/ResultsRsast/Server17_Comparison_RSAST')\n",
    "directories.append(os.getcwd()+'/ResultsRsast/Server17_Comparison_RSAST_All')\n",
    "#directories.append(os.getcwd()+'/ResultsRsast/Server16_Hyperparameter_Tunning')\n",
    "#directories.append(os.getcwd()+'/ResultsRsast/Server17_Hyperparameter_Tunning')\n",
    "#directories.append(os.getcwd()+'/results_accuracy_per_ds')\n",
    "#directories.append(os.getcwd()+'/results_accuracy_per_ds_10000')\n",
    "\n",
    "\n",
    "# Create an empty list to store the dataframes\n",
    "dfs = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for directory in directories:\n",
    "    for filename in os.listdir(directory):\n",
    "        # Check if the file starts with \"df_overall_tunning\" and ends with \".csv\"\n",
    "        if filename.startswith(\"df_all_overall_tunning\") and filename.endswith(\".csv\"):\n",
    "            # Read the csv file into a dataframe\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            df = pd.read_csv(filepath)\n",
    "            df['rpoint']=df['rpoint'].astype(str)\n",
    "            df['nb_per_class']=df['nb_per_class'].astype(str)\n",
    "            df['rpoint']=df['rpoint'].replace(\"(lenthg ts)//2\",\"half_len\")\n",
    "            df['nb_per_class']=df['nb_per_class'].replace(\"(max instances per class)//2\",\"half_instance\")\n",
    "            df['classifier_name']=df['classifier_name'].str.replace(\"\\(lenthg ts\\)//2\",\"half_len\")\n",
    "            df['classifier_name']=df['classifier_name'].str.replace(\"\\(max instances per class\\)//2\",\"half_instance\")\n",
    "            # Append the dataframe to the list\n",
    "            dfs.append(df)\n",
    "\n",
    "# Concatenate all the dataframes in the list into one dataframe\n",
    "df_result = pd.concat(dfs, ignore_index=True)\n",
    "# df_result.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['USED SAST', 'BAKE OFF', 'N RUNS S17_S16_HT', 'N RUNS S17_SAST_DS',\n",
       "       'ID', 'Name', 'Type', 'Train ', 'Test ', 'Class', 'Length',\n",
       "       'RSAST (10,10) WORST SAST?', 'O(|c|nm²)', 'O(|c|nm³)',\n",
       "       'Approx Time (hours)', 'L25', 'L50', 'L75', 'ED (w=0)',\n",
       "       'DTW (learned_w) ', 'DTW (w=100)', 'Default rate', 'Data donor/editor',\n",
       "       '50/L', 'Unnamed: 24'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_used_sast=pd.read_excel(\"DataSetsUCLASummary.xlsx\", dtype=str)\n",
    "df_used_sast.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>Class</th>\n",
       "      <th>Length</th>\n",
       "      <th>USED SAST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SmoothSubspace</td>\n",
       "      <td>Simulated</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chinatown</td>\n",
       "      <td>Traffic</td>\n",
       "      <td>20</td>\n",
       "      <td>343</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ItalyPowerDemand</td>\n",
       "      <td>Sensor</td>\n",
       "      <td>67</td>\n",
       "      <td>1029</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MelbournePedestrian</td>\n",
       "      <td>Traffic</td>\n",
       "      <td>1194</td>\n",
       "      <td>2439</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Crop</td>\n",
       "      <td>Image</td>\n",
       "      <td>7200</td>\n",
       "      <td>16800</td>\n",
       "      <td>24</td>\n",
       "      <td>46</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>BeetleFly</td>\n",
       "      <td>Image</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>BirdChicken</td>\n",
       "      <td>Image</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Herring</td>\n",
       "      <td>Image</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Earthquakes</td>\n",
       "      <td>Sensor</td>\n",
       "      <td>322</td>\n",
       "      <td>139</td>\n",
       "      <td>2</td>\n",
       "      <td>512</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Car</td>\n",
       "      <td>Sensor</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>577</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name       Type Train   Test  Class Length USED SAST\n",
       "0        SmoothSubspace  Simulated    150    150     3     15         Y\n",
       "1             Chinatown    Traffic     20    343     2     24         Y\n",
       "2      ItalyPowerDemand     Sensor     67   1029     2     24         Y\n",
       "3   MelbournePedestrian    Traffic   1194   2439    10     24         Y\n",
       "4                  Crop      Image   7200  16800    24     46         Y\n",
       "..                  ...        ...    ...    ...   ...    ...       ...\n",
       "77            BeetleFly      Image     20     20     2    512         Y\n",
       "78          BirdChicken      Image     20     20     2    512         Y\n",
       "79              Herring      Image     64     64     2    512         Y\n",
       "80          Earthquakes     Sensor    322    139     2    512         Y\n",
       "82                  Car     Sensor     60     60     4    577         Y\n",
       "\n",
       "[72 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_used_sast=df_used_sast[['Name', 'Type', 'Train ', 'Test ', 'Class', 'Length','USED SAST']]\n",
    "df_used_sast=df_used_sast[df_used_sast['USED SAST']=='Y']\n",
    "df_used_sast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nlen_methods=['ACF&PACF: n_random_points=30 nb_inst_per_class=1',\\n'ACF&PACF: n_random_points=10 nb_inst_per_class=10',\\n'None: n_random_points=30 nb_inst_per_class=1',\\n'None: n_random_points=10 nb_inst_per_class=10'\\n]\\ndf_result=df_result[df_result.classifier_name.isin(len_methods)]\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "len_methods=['ACF&PACF: n_random_points=30 nb_inst_per_class=1',\n",
    "'ACF&PACF: n_random_points=10 nb_inst_per_class=10',\n",
    "'None: n_random_points=30 nb_inst_per_class=1',\n",
    "'None: n_random_points=10 nb_inst_per_class=10'\n",
    "]\n",
    "df_result=df_result[df_result.classifier_name.isin(len_methods)]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total DS:5\n"
     ]
    }
   ],
   "source": [
    "#get ds tested overall\n",
    "print(\"Total DS:\" + str(len(df_result['dataset_name'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ItalyPowerDemand', 'SmoothSubspace', 'Chinatown', 'Crop',\n",
       "       'SyntheticControl'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get ds tested overall\n",
    "df_result['dataset_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Param Combination:4\n"
     ]
    }
   ],
   "source": [
    "#get ds tested overall\n",
    "print(\"Total Param Combination:\" + str(len(df_result['classifier_name'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['all: n_random_points=10 nb_inst_per_class=1',\n",
       "       'all: n_random_points=10 nb_inst_per_class=10',\n",
       "       'all: n_random_points=30 nb_inst_per_class=1',\n",
       "       'all: n_random_points=30 nb_inst_per_class=10'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get len methods of generated datasets\n",
    "df_result.classifier_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'accuracy', 'time', 'cweights_time', 'fsubsequence_time',\n",
       "       'tdataset_time', 'tclassifier_time', 'dataset_name', 'classifier_name',\n",
       "       'rpoint', 'nb_per_class', 'method', 'len_method'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get columns of generated datasets\n",
    "df_result.columns.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>classifier_name</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>all: n_random_points=10 nb_inst_per_class=1</th>\n",
       "      <th>all: n_random_points=10 nb_inst_per_class=10</th>\n",
       "      <th>all: n_random_points=30 nb_inst_per_class=1</th>\n",
       "      <th>all: n_random_points=30 nb_inst_per_class=10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinatown</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.985423</td>\n",
       "      <td>0.977259</td>\n",
       "      <td>0.985423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crop</td>\n",
       "      <td>0.634568</td>\n",
       "      <td>0.744851</td>\n",
       "      <td>0.701875</td>\n",
       "      <td>0.750417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ItalyPowerDemand</td>\n",
       "      <td>0.952187</td>\n",
       "      <td>0.954908</td>\n",
       "      <td>0.956074</td>\n",
       "      <td>0.953741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SmoothSubspace</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.822667</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SyntheticControl</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>0.975333</td>\n",
       "      <td>0.992000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "classifier_name      dataset_name  \\\n",
       "0                       Chinatown   \n",
       "1                            Crop   \n",
       "2                ItalyPowerDemand   \n",
       "3                  SmoothSubspace   \n",
       "4                SyntheticControl   \n",
       "\n",
       "classifier_name  all: n_random_points=10 nb_inst_per_class=1  \\\n",
       "0                                                   0.971429   \n",
       "1                                                   0.634568   \n",
       "2                                                   0.952187   \n",
       "3                                                   0.804000   \n",
       "4                                                   0.963333   \n",
       "\n",
       "classifier_name  all: n_random_points=10 nb_inst_per_class=10  \\\n",
       "0                                                    0.985423   \n",
       "1                                                    0.744851   \n",
       "2                                                    0.954908   \n",
       "3                                                    0.940000   \n",
       "4                                                    0.990667   \n",
       "\n",
       "classifier_name  all: n_random_points=30 nb_inst_per_class=1  \\\n",
       "0                                                   0.977259   \n",
       "1                                                   0.701875   \n",
       "2                                                   0.956074   \n",
       "3                                                   0.822667   \n",
       "4                                                   0.975333   \n",
       "\n",
       "classifier_name  all: n_random_points=30 nb_inst_per_class=10  \n",
       "0                                                    0.985423  \n",
       "1                                                    0.750417  \n",
       "2                                                    0.953741  \n",
       "3                                                    0.940000  \n",
       "4                                                    0.992000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df_result, index=\"dataset_name\", values=\"accuracy\", columns=\"classifier_name\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndf_tunned_rsast=df_used_sast.merge(pd.pivot_table(df_result, index=\"dataset_name\", values=\"accuracy\", columns=\"classifier_name\").reset_index(),how=\\'right\\',right_on=\"dataset_name\",left_on=\"Name\").round(2)[[\\'Name\\', \\'ACF&PACF: n_random_points=30 nb_inst_per_class=10\\',\\'ACF&PACF: n_random_points=30 nb_inst_per_class=10\\',\\'ACF&PACF: n_random_points=30 nb_inst_per_class=1\\',\\'Type\\', \\'Train \\', \\'Test \\', \\'Class\\', \\'Length\\']]\\ndf_tunned_rsast.sort_values(\"Name\",inplace=True)\\ndf_tunned_rsast.to_excel(\\'ds_runned_rsast.xlsx\\')\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "df_tunned_rsast=df_used_sast.merge(pd.pivot_table(df_result, index=\"dataset_name\", values=\"accuracy\", columns=\"classifier_name\").reset_index(),how='right',right_on=\"dataset_name\",left_on=\"Name\").round(2)[['Name', 'ACF&PACF: n_random_points=30 nb_inst_per_class=10','ACF&PACF: n_random_points=30 nb_inst_per_class=10','ACF&PACF: n_random_points=30 nb_inst_per_class=1','Type', 'Train ', 'Test ', 'Class', 'Length']]\n",
    "df_tunned_rsast.sort_values(\"Name\",inplace=True)\n",
    "df_tunned_rsast.to_excel('ds_runned_rsast.xlsx')\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tunning RSAST "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy: Subsequence Lenght Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ItalyPowerDemand', 'SmoothSubspace', 'Chinatown', 'Crop',\n",
       "       'SyntheticControl'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_param=df_result\n",
    "\n",
    "#filter_param=filter_param[filter_param.len_method=='ACF&PACF']\n",
    "filter_param.dataset_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '30'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_param.rpoint.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_param=filter_param[filter_param.rpoint=='half_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '10'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_param.nb_per_class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_param=filter_param[filter_param.nb_per_class=='30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>all</th>\n",
       "      <th>score</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinatown</td>\n",
       "      <td>0.979883</td>\n",
       "      <td>0.96</td>\n",
       "      <td>SAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crop</td>\n",
       "      <td>0.707928</td>\n",
       "      <td>0.73</td>\n",
       "      <td>SAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ItalyPowerDemand</td>\n",
       "      <td>0.954227</td>\n",
       "      <td>0.96</td>\n",
       "      <td>SAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SmoothSubspace</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.91</td>\n",
       "      <td>SAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SyntheticControl</td>\n",
       "      <td>0.980333</td>\n",
       "      <td>0.98</td>\n",
       "      <td>SAST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset_name       all  score method\n",
       "0         Chinatown  0.979883   0.96   SAST\n",
       "1              Crop  0.707928   0.73   SAST\n",
       "2  ItalyPowerDemand  0.954227   0.96   SAST\n",
       "3    SmoothSubspace  0.876667   0.91   SAST\n",
       "4  SyntheticControl  0.980333   0.98   SAST"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pivot table with the mean of score by dataset\n",
    "len_method_vs_ds=pd.pivot_table(filter_param, values='accuracy', index=['len_method'],columns=['dataset_name'], aggfunc='mean')\n",
    "len_method_vs_ds=np.transpose(len_method_vs_ds)#[['ACF','PACF']]\n",
    "len_method_vs_ds=len_method_vs_ds.reset_index()\n",
    "df_rocket=df_other_methods[df_other_methods[\"method\"]==\"SAST\"]\n",
    "merged_df = len_method_vs_ds.merge(df_rocket,left_on='dataset_name', right_on='dataset',  how='left')\n",
    "merged_df=merged_df.drop('dataset',axis=1)\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.899808</td>\n",
       "      <td>0.908000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.115338</td>\n",
       "      <td>0.102811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.707928</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.954227</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.979883</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.980333</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            all     score\n",
       "count  5.000000  5.000000\n",
       "mean   0.899808  0.908000\n",
       "std    0.115338  0.102811\n",
       "min    0.707928  0.730000\n",
       "25%    0.876667  0.910000\n",
       "50%    0.954227  0.960000\n",
       "75%    0.979883  0.960000\n",
       "max    0.980333  0.980000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>SE</th>\n",
       "      <th>95% Conf.</th>\n",
       "      <th>Interval</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Chinatown</th>\n",
       "      <td>20</td>\n",
       "      <td>0.9799</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.9837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crop</th>\n",
       "      <td>16</td>\n",
       "      <td>0.7079</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.6824</td>\n",
       "      <td>0.7334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItalyPowerDemand</th>\n",
       "      <td>20</td>\n",
       "      <td>0.9542</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.9515</td>\n",
       "      <td>0.9569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SmoothSubspace</th>\n",
       "      <td>20</td>\n",
       "      <td>0.8767</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.8441</td>\n",
       "      <td>0.9092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SyntheticControl</th>\n",
       "      <td>20</td>\n",
       "      <td>0.9803</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.9741</td>\n",
       "      <td>0.9865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   N    Mean      SD      SE  95% Conf.  Interval\n",
       "dataset_name                                                     \n",
       "Chinatown         20  0.9799  0.0081  0.0018     0.9761    0.9837\n",
       "Crop              16  0.7079  0.0479  0.0120     0.6824    0.7334\n",
       "ItalyPowerDemand  20  0.9542  0.0058  0.0013     0.9515    0.9569\n",
       "SmoothSubspace    20  0.8767  0.0696  0.0156     0.8441    0.9092\n",
       "SyntheticControl  20  0.9803  0.0132  0.0030     0.9741    0.9865"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Summary statistics for a Series (single variable)\n",
    "\n",
    "summ_ds=filter_param\n",
    "summ_ds=researchpy.summary_cont(summ_ds.groupby(['dataset_name'])['accuracy'], conf = 0.95)\n",
    "summ_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                mean  count      std   ci95_hi   ci95_lo\n",
      "len_method                                              \n",
      "all         0.907803     96  0.10475  0.928757  0.886848\n"
     ]
    }
   ],
   "source": [
    "stats = filter_param.groupby(['len_method'])['accuracy'].agg(['mean', 'count', 'std'])\n",
    "\n",
    "ci95_hi = []\n",
    "ci95_lo = []\n",
    "\n",
    "for i in stats.index:\n",
    "    m, c, s = stats.loc[i]\n",
    "    ci95_hi.append(m + 1.96*s/math.sqrt(c))\n",
    "    ci95_lo.append(m - 1.96*s/math.sqrt(c))\n",
    "\n",
    "stats['ci95_hi'] = ci95_hi\n",
    "stats['ci95_lo'] = ci95_lo\n",
    "print(stats.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Boxplot Tunning Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '10'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.nb_per_class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['all'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.len_method.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate hyperparameter tuning boxplots\n",
    "\n",
    "for k, ints in enumerate(df_result.nb_per_class.unique()):\n",
    "\n",
    "    for len_m in df_result.len_method.unique():\n",
    "        \n",
    "        \n",
    "        df_to_cd=df_result[df_result.classifier_name.str.contains(r'^'+len_m+':.*nb_inst_per_class='+str(ints)+'$')]\n",
    "        #df_to_cd=pd.pivot_table(df_to_cd, index=['dataset_name','classifier_name'], columns=['rpoint'],values='accuracy')\n",
    "        #df_to_cd = df_to_cd.reindex(columns=[\"1\",\"10\",\"30\",\"50\",\"100\",\"half_len\"])\n",
    "        \n",
    "        #print(df_to_cd.head(5))\n",
    "\n",
    "        # Plot\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "        \n",
    "        #order=list(df_to_cd)\n",
    "        sns.boxplot(data=df_to_cd, x='rpoint', y='accuracy', palette=\"Blues\")\n",
    "        #plt.boxplot(df_to_cd, labels=list(df_to_cd), showfliers=False)\n",
    "        \n",
    "        max_bx=max(df_to_cd.accuracy)\n",
    "        min_bx=min(df_to_cd.accuracy)\n",
    "        ax.set_ylim(min_bx,max_bx)\n",
    "        # Axis details\n",
    "        ax.set(xlabel='number of random points', ylabel='accuracy', title='Accuracy Boxplot for Len method:'+len_m+' and N° of Instances:'+ints)\n",
    "        #plt.xticks([1, 2, 3, 4, 5, 6],list(df_to_cd) )\n",
    "        #print(df_to_cd.describe())\n",
    "\n",
    "        # save plot\n",
    "        plt.savefig('images_boxplot_acc/boxplot_acc'+len_m+ints+'.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['all: n_random_points=10 nb_inst_per_class=1',\n",
       "       'all: n_random_points=10 nb_inst_per_class=10',\n",
       "       'all: n_random_points=30 nb_inst_per_class=1',\n",
       "       'all: n_random_points=30 nb_inst_per_class=10'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.classifier_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds:ItalyPowerDemand\n",
      "ints:1\n",
      "len_m:all\n",
      "ds:ItalyPowerDemand\n",
      "ints:10\n",
      "len_m:all\n",
      "ds:SmoothSubspace\n",
      "ints:1\n",
      "len_m:all\n",
      "ds:SmoothSubspace\n",
      "ints:10\n",
      "len_m:all\n",
      "ds:Chinatown\n",
      "ints:1\n",
      "len_m:all\n",
      "ds:Chinatown\n",
      "ints:10\n",
      "len_m:all\n",
      "ds:Crop\n",
      "ints:1\n",
      "len_m:all\n",
      "ds:Crop\n",
      "ints:10\n",
      "len_m:all\n",
      "ds:SyntheticControl\n",
      "ints:1\n",
      "len_m:all\n",
      "ds:SyntheticControl\n",
      "ints:10\n",
      "len_m:all\n"
     ]
    }
   ],
   "source": [
    "#generate hyperparameter tuning boxplots\n",
    "for ds in df_result.dataset_name.unique():\n",
    "    for k, ints in enumerate(df_result.nb_per_class.unique()):\n",
    "        for len_m in df_result.len_method.unique():\n",
    "            print(\"ds:\"+ds)\n",
    "            print(\"ints:\"+str(ints))\n",
    "            print(\"len_m:\"+len_m)\n",
    "\n",
    "            df_to_cd=df_result[df_result.classifier_name.str.contains(r'^'+len_m+':')]\n",
    "            df_to_cd=df_to_cd[df_to_cd.dataset_name==ds]\n",
    "\n",
    "            df_to_cd[\"time\"]=df_to_cd['cweights_time']+df_to_cd['fsubsequence_time']+df_to_cd['tdataset_time']\n",
    "            df_to_cd[\"time\"]=df_to_cd[\"time\"]/60\n",
    "            max_bx=max(df_to_cd.accuracy)\n",
    "            min_bx=min(df_to_cd.accuracy)\n",
    "            \n",
    "            df_to_cd=df_to_cd[df_to_cd.classifier_name.str.contains(r':.*nb_inst_per_class='+str(ints)+'$')]    \n",
    "\n",
    "            #df_to_cd=pd.pivot_table(df_to_cd, index=['dataset_name','classifier_name'], columns=['rpoint'],values='accuracy')\n",
    "            #df_to_cd = df_to_cd.reindex(columns=[\"1\",\"10\",\"30\",\"50\",\"100\",\"half_len\"])\n",
    "            \n",
    "            #print(df_to_cd.head(5))\n",
    "\n",
    "            # Plot\n",
    "            fig, ax = plt.subplots()\n",
    "            \n",
    "            \n",
    "            #order=list(df_to_cd)\n",
    "            sns.boxplot(data=df_to_cd, x='rpoint', y='accuracy', palette=\"Blues\")\n",
    "            #plt.boxplot(df_to_cd, labels=list(df_to_cd), showfliers=False)\n",
    "            \n",
    "            ax.set_ylim(min_bx,max_bx)\n",
    "            # Axis details\n",
    "            ax.set(xlabel='number of random points', ylabel='accuracy', title='Accuracy Boxplot for Len method:'+len_m+' and N° of Instances:'+ints)\n",
    "            #plt.xticks([1, 2, 3, 4, 5, 6],list(df_to_cd) )\n",
    "            #print(df_to_cd.describe())\n",
    "\n",
    "            # save plot\n",
    "            plt.savefig('images_boxplot_acc_per_ds/boxplot_acc'+len_m+ints+'_'+ds+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6569/4020300904.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_to_cd[\"time\"]=df_to_cd['cweights_time']+df_to_cd['fsubsequence_time']+df_to_cd['tdataset_time']\n",
      "/tmp/ipykernel_6569/4020300904.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_to_cd[\"time\"]=df_to_cd[\"time\"]/60\n",
      "/tmp/ipykernel_6569/4020300904.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_to_cd[\"time\"]=df_to_cd['cweights_time']+df_to_cd['fsubsequence_time']+df_to_cd['tdataset_time']\n",
      "/tmp/ipykernel_6569/4020300904.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_to_cd[\"time\"]=df_to_cd[\"time\"]/60\n"
     ]
    }
   ],
   "source": [
    "#generate hyperparameter tuning boxplots\n",
    "\n",
    "for k, ints in enumerate(df_result.nb_per_class.unique()):\n",
    "    for len_m in df_result.len_method.unique():\n",
    "        \n",
    "        \n",
    "        df_to_cd=df_result[df_result.classifier_name.str.contains(r'^'+len_m+':.*nb_inst_per_class='+str(ints)+'$')]\n",
    "        df_to_cd[\"time\"]=df_to_cd['cweights_time']+df_to_cd['fsubsequence_time']+df_to_cd['tdataset_time']\n",
    "        df_to_cd[\"time\"]=df_to_cd[\"time\"]/60\n",
    "        #df_to_cd=pd.pivot_table(df_to_cd, index=['dataset_name','classifier_name'], columns=['rpoint'],values='accuracy')\n",
    "        #df_to_cd = df_to_cd.reindex(columns=[\"1\",\"10\",\"30\",\"50\",\"100\",\"half_len\"])\n",
    "        \n",
    "        #print(df_to_cd.head(5))\n",
    "\n",
    "        # Plot\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "        \n",
    "        #order=list(df_to_cd)\n",
    "        sns.boxplot(data=df_to_cd, x='rpoint', y='time', palette=\"Blues\")\n",
    "        #plt.boxplot(df_to_cd, labels=list(df_to_cd), showfliers=False)\n",
    "        \n",
    "        max_bx=max(df_to_cd.time)\n",
    "        min_bx=min(df_to_cd.time)\n",
    "        ax.set_ylim(min_bx,max_bx)\n",
    "        # Axis details\n",
    "        ax.set(xlabel='number of random points', ylabel='time', title='Time Boxplot for Len method:'+len_m+' and N° of Instances:'+ints)\n",
    "        #plt.xticks([1, 2, 3, 4, 5, 6],list(df_to_cd) )\n",
    "        #print(df_to_cd.describe())\n",
    "\n",
    "        # save plot\n",
    "        plt.savefig('images_boxplot_time/boxplot_time'+len_m+ints+'.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6569/215494581.py:25: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots()\n"
     ]
    }
   ],
   "source": [
    "#generate hyperparameter tuning boxplots\n",
    "for ds in df_result.dataset_name.unique():\n",
    "    for k, ints in enumerate(df_result.nb_per_class.unique()):\n",
    "        for len_m in df_result.len_method.unique():\n",
    "        \n",
    "\n",
    "\n",
    "            df_to_cd=df_result[df_result.classifier_name.str.contains(r'^'+len_m+':')]\n",
    "            df_to_cd=df_to_cd[df_to_cd.dataset_name==ds]\n",
    "\n",
    "            df_to_cd[\"time\"]=df_to_cd['cweights_time']+df_to_cd['fsubsequence_time']+df_to_cd['tdataset_time']\n",
    "            df_to_cd[\"time\"]=df_to_cd[\"time\"]/60\n",
    "            max_bx=max(df_to_cd.time)\n",
    "            min_bx=min(df_to_cd.time)\n",
    "\n",
    "            df_to_cd=df_to_cd[df_to_cd.classifier_name.str.contains(r':.*nb_inst_per_class='+str(ints)+'$')]\n",
    "\n",
    "\n",
    "            #df_to_cd=pd.pivot_table(df_to_cd, index=['dataset_name','classifier_name'], columns=['rpoint'],values='accuracy')\n",
    "            #df_to_cd = df_to_cd.reindex(columns=[\"1\",\"10\",\"30\",\"50\",\"100\",\"half_len\"])\n",
    "            \n",
    "            #print(df_to_cd.head(5))\n",
    "\n",
    "            # Plot\n",
    "            fig, ax = plt.subplots()\n",
    "            \n",
    "            \n",
    "            #order=list(df_to_cd)\n",
    "            sns.boxplot(data=df_to_cd, x='rpoint', y='time', palette=\"Blues\")\n",
    "            #plt.boxplot(df_to_cd, labels=list(df_to_cd), showfliers=False)\n",
    "            \n",
    "\n",
    "            ax.set_ylim(min_bx,max_bx)\n",
    "            # Axis details\n",
    "            ax.set(xlabel='number of random points', ylabel='time', title='Time Boxplot for Len method:'+len_m+' and N° of Instances:'+ints)\n",
    "            #plt.xticks([1, 2, 3, 4, 5, 6],list(df_to_cd) )\n",
    "            #print(df_to_cd.describe())\n",
    "\n",
    "            # save plot\n",
    "            plt.savefig('images_boxplot_time_per_ds/boxplot_time'+len_m+ints+'_'+ds+'.png')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate CD Diagram Tunning Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['all: n_random_points=10 nb_inst_per_class=1',\n",
       "       'all: n_random_points=10 nb_inst_per_class=10',\n",
       "       'all: n_random_points=30 nb_inst_per_class=1',\n",
       "       'all: n_random_points=30 nb_inst_per_class=10'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_perf=pd.pivot_table(df_result, values='accuracy', index=['classifier_name','dataset_name'], aggfunc='mean')\n",
    "df_perf=df_perf.reset_index()\n",
    "df_perf.classifier_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_m=\"None\"\n",
    "ints=\"10\"\n",
    "df_perf[df_perf.classifier_name.str.contains(r'^'+len_m+':.*$')].classifier_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nirojasvar/anaconda3/envs/rsast_env/lib/python3.10/site-packages/scipy/stats/_morestats.py:3414: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/home/nirojasvar/anaconda3/envs/rsast_env/lib/python3.10/site-packages/scipy/stats/_morestats.py:3428: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'all: n_random_points=10 nb_inst_per_class=1', 1: 'all: n_random_points=30 nb_inst_per_class=1', 2: 'all: n_random_points=10 nb_inst_per_class=10', 3: 'all: n_random_points=30 nb_inst_per_class=10'}\n",
      "[0, 1, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "/home/nirojasvar/anaconda3/envs/rsast_env/lib/python3.10/site-packages/scipy/stats/_morestats.py:3414: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/home/nirojasvar/anaconda3/envs/rsast_env/lib/python3.10/site-packages/scipy/stats/_morestats.py:3428: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from cd_function import *\n",
    "#generate hyperparameter tuning cd diagrams\n",
    "\n",
    "best_comb_by_method=[]\n",
    "best=\"\"\n",
    "for len_m in df_result.len_method.unique():\n",
    "   df_to_cd=df_perf[df_perf.classifier_name.str.contains(r'^'+len_m+':.*$')]\n",
    "   draw_cd_diagram(df_to_cd, labels=True, title=len_m +\" comparison\", fname='images_cd_diagram/cd-diagram_'+len_m+'.png')\n",
    "   _, average_ranks, _ = wilcoxon_holm(df_perf=df_to_cd)\n",
    "   min_rank= min(average_ranks)\n",
    "   average_ranks=pd.DataFrame(average_ranks)\n",
    "   best=average_ranks[average_ranks[0]==min_rank][0].index\n",
    "   best_comb_by_method.append(best[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(best_comb_by_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6569/2209284884.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_to_cd=df_perf[df_result.classifier_name.isin(best_comb_by_method)]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "At least 3 sets of samples must be given for Friedman test, got 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df_to_cd\u001b[39m=\u001b[39mdf_perf[df_result\u001b[39m.\u001b[39mclassifier_name\u001b[39m.\u001b[39misin(best_comb_by_method)]\n\u001b[0;32m----> 2\u001b[0m draw_cd_diagram(df_to_cd, labels\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, title\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mBest combination comparison\u001b[39;49m\u001b[39m\"\u001b[39;49m, fname\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mimages_cd_diagram/cd-diagram_best_com.png\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/random_sast/cd_diagram/cd_function.py:278\u001b[0m, in \u001b[0;36mdraw_cd_diagram\u001b[0;34m(df_perf, alpha, title, labels, fname, fig_width, linesblank)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_cd_diagram\u001b[39m(df_perf\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, alpha\u001b[39m=\u001b[39m\u001b[39m0.05\u001b[39m, title\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, labels\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, fname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, fig_width\u001b[39m=\u001b[39m\u001b[39m9\u001b[39m, linesblank \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m    274\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[39m    Draws the critical difference diagram given the list of pairwise classifiers that are\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[39m    significant or not\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m     p_values, average_ranks, _ \u001b[39m=\u001b[39m wilcoxon_holm(df_perf\u001b[39m=\u001b[39;49mdf_perf, alpha\u001b[39m=\u001b[39;49malpha)\n\u001b[1;32m    280\u001b[0m     \u001b[39m# print(average_ranks)\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \n\u001b[1;32m    282\u001b[0m     \u001b[39m# for p in p_values:\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     \u001b[39m#     print(p)\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     graph_ranks(average_ranks\u001b[39m.\u001b[39mvalues, average_ranks\u001b[39m.\u001b[39mkeys(), p_values,\n\u001b[1;32m    287\u001b[0m                 cd\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, width\u001b[39m=\u001b[39mfig_width, textspace\u001b[39m=\u001b[39m\u001b[39m1.5\u001b[39m, labels\u001b[39m=\u001b[39mlabels, linesblank \u001b[39m=\u001b[39m linesblank)\n",
      "File \u001b[0;32m~/random_sast/cd_diagram/cd_function.py:315\u001b[0m, in \u001b[0;36mwilcoxon_holm\u001b[0;34m(alpha, df_perf)\u001b[0m\n\u001b[1;32m    312\u001b[0m classifiers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(df_counts\u001b[39m.\u001b[39mloc[df_counts[\u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m max_nb_datasets]\n\u001b[1;32m    313\u001b[0m                    [\u001b[39m'\u001b[39m\u001b[39mclassifier_name\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    314\u001b[0m \u001b[39m# test the null hypothesis using friedman before doing a post-hoc analysis\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m friedman_p_value \u001b[39m=\u001b[39m friedmanchisquare(\u001b[39m*\u001b[39;49m(\n\u001b[1;32m    316\u001b[0m     np\u001b[39m.\u001b[39;49marray(df_perf\u001b[39m.\u001b[39;49mloc[df_perf[\u001b[39m'\u001b[39;49m\u001b[39mclassifier_name\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49m c][\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    317\u001b[0m     \u001b[39mfor\u001b[39;49;00m c \u001b[39min\u001b[39;49;00m classifiers))[\u001b[39m1\u001b[39m]\n\u001b[1;32m    318\u001b[0m \u001b[39mif\u001b[39;00m friedman_p_value \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m alpha:\n\u001b[1;32m    319\u001b[0m     \u001b[39m# then the null hypothesis over the entire classifiers cannot be rejected\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mthe null hypothesis over the entire classifiers cannot be rejected\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/rsast_env/lib/python3.10/site-packages/scipy/stats/_stats_py.py:8673\u001b[0m, in \u001b[0;36mfriedmanchisquare\u001b[0;34m(*samples)\u001b[0m\n\u001b[1;32m   8671\u001b[0m k \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(samples)\n\u001b[1;32m   8672\u001b[0m \u001b[39mif\u001b[39;00m k \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m-> 8673\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAt least 3 sets of samples must be given \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   8674\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mfor Friedman test, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k))\n\u001b[1;32m   8676\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(samples[\u001b[39m0\u001b[39m])\n\u001b[1;32m   8677\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, k):\n",
      "\u001b[0;31mValueError\u001b[0m: At least 3 sets of samples must be given for Friedman test, got 1."
     ]
    }
   ],
   "source": [
    "\n",
    "df_to_cd=df_perf[df_result.classifier_name.isin(best_comb_by_method)]\n",
    "draw_cd_diagram(df_to_cd, labels=True, title=\"Best combination comparison\", fname='images_cd_diagram/cd-diagram_best_com.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nirojasvar/anaconda3/envs/rsast_env/lib/python3.10/site-packages/scipy/stats/_morestats.py:3414: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/home/nirojasvar/anaconda3/envs/rsast_env/lib/python3.10/site-packages/scipy/stats/_morestats.py:3428: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'all: n_random_points=10 nb_inst_per_class=1', 1: 'all: n_random_points=30 nb_inst_per_class=1', 2: 'all: n_random_points=10 nb_inst_per_class=10', 3: 'all: n_random_points=30 nb_inst_per_class=10'}\n",
      "[0, 1, 2, 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial\n"
     ]
    }
   ],
   "source": [
    "draw_cd_diagram(df_perf, labels=True, fname='images_cd_diagram/cd-diagram_all.png')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Focus on most accurate lenght method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overall Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all: n_random_points=30 nb_inst_per_class=10']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# highest accurate hyperparameters\n",
    "best_comb_by_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>nb_per_class</th>\n",
       "      <th>half_instance</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>30</th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rpoint</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>half_len</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.874709</td>\n",
       "      <td>0.930600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.894340</td>\n",
       "      <td>0.931562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "nb_per_class  half_instance         1        10  30  50  100  1000  10000\n",
       "rpoint                                                                   \n",
       "half_len                NaN       NaN       NaN NaN NaN  NaN   NaN    NaN\n",
       "1                       NaN       NaN       NaN NaN NaN  NaN   NaN    NaN\n",
       "10                      NaN  0.874709  0.930600 NaN NaN  NaN   NaN    NaN\n",
       "30                      NaN  0.894340  0.931562 NaN NaN  NaN   NaN    NaN\n",
       "50                      NaN       NaN       NaN NaN NaN  NaN   NaN    NaN\n",
       "100                     NaN       NaN       NaN NaN NaN  NaN   NaN    NaN\n",
       "1000                    NaN       NaN       NaN NaN NaN  NaN   NaN    NaN\n",
       "10000                   NaN       NaN       NaN NaN NaN  NaN   NaN    NaN"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter by method with ACF&PACF\n",
    "# create a pivot table with the mean of score by hyperparameter\n",
    "df_result_acc=df_result\n",
    "#df_result_acc=df_result_acc[df_result_acc[\"dataset_name\"]==\"Fungi\"]\n",
    "\n",
    "pivot = pd.pivot_table(df_result_acc, values='accuracy', index=['rpoint'],columns=['nb_per_class'], aggfunc='mean')\n",
    "pivot = pivot.reindex(columns=[\"half_instance\",\"1\",\"10\",\"30\",\"50\",\"100\",\"1000\",\"10000\"], index=[\"half_len\",\"1\",\"10\",\"30\",\"50\",\"100\",\"1000\",\"10000\"])\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>nb_per_class</th>\n",
       "      <th>half_instance</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>30</th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rpoint</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>half_len</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020639</td>\n",
       "      <td>0.019543</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022631</td>\n",
       "      <td>0.019377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "nb_per_class  half_instance         1        10  30  50  100  1000  10000\n",
       "rpoint                                                                   \n",
       "half_len                NaN       NaN       NaN NaN NaN  NaN   NaN    NaN\n",
       "1                       NaN       NaN       NaN NaN NaN  NaN   NaN    NaN\n",
       "10                      NaN  0.020639  0.019543 NaN NaN  NaN   NaN    NaN\n",
       "30                      NaN  0.022631  0.019377 NaN NaN  NaN   NaN    NaN\n",
       "50                      NaN       NaN       NaN NaN NaN  NaN   NaN    NaN\n",
       "100                     NaN       NaN       NaN NaN NaN  NaN   NaN    NaN\n",
       "1000                    NaN       NaN       NaN NaN NaN  NaN   NaN    NaN\n",
       "10000                   NaN       NaN       NaN NaN NaN  NaN   NaN    NaN"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pivot table with the variatioon of score by hyperparameter\n",
    "pivot = pd.pivot_table(df_result_acc, values='accuracy', index=['rpoint'],columns=['nb_per_class'], aggfunc='var')\n",
    "pivot = pivot.reindex(columns=[\"half_instance\",\"1\",\"10\",\"30\",\"50\",\"100\",\"1000\",\"10000\"], index=[\"half_len\",\"1\",\"10\",\"30\",\"50\",\"100\",\"1000\",\"10000\"])\n",
    "pivot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overall time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.857479894351628"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_acc.time.sum()/(60*60*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cweights_time</th>\n",
       "      <th>fsubsequence_time</th>\n",
       "      <th>tdataset_time</th>\n",
       "      <th>tclassifier_time</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adiac</th>\n",
       "      <td>0.356932</td>\n",
       "      <td>6.251375</td>\n",
       "      <td>867.444809</td>\n",
       "      <td>5.253082</td>\n",
       "      <td>879.326493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ArrowHead</th>\n",
       "      <td>0.068162</td>\n",
       "      <td>2.550791</td>\n",
       "      <td>14.467688</td>\n",
       "      <td>0.137025</td>\n",
       "      <td>17.226493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BME</th>\n",
       "      <td>0.037609</td>\n",
       "      <td>0.291632</td>\n",
       "      <td>3.115769</td>\n",
       "      <td>0.036141</td>\n",
       "      <td>3.482713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beef</th>\n",
       "      <td>0.141614</td>\n",
       "      <td>36.995622</td>\n",
       "      <td>58.747155</td>\n",
       "      <td>0.014530</td>\n",
       "      <td>95.910451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BeetleFly</th>\n",
       "      <td>0.094815</td>\n",
       "      <td>33.239842</td>\n",
       "      <td>16.043617</td>\n",
       "      <td>0.007177</td>\n",
       "      <td>49.390765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TwoPatterns</th>\n",
       "      <td>0.093418</td>\n",
       "      <td>0.414763</td>\n",
       "      <td>118.326124</td>\n",
       "      <td>4.722428</td>\n",
       "      <td>123.560247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UMD</th>\n",
       "      <td>0.043190</td>\n",
       "      <td>0.443225</td>\n",
       "      <td>5.108370</td>\n",
       "      <td>0.119882</td>\n",
       "      <td>5.716431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wafer</th>\n",
       "      <td>0.082004</td>\n",
       "      <td>0.327180</td>\n",
       "      <td>50.331497</td>\n",
       "      <td>1.112268</td>\n",
       "      <td>51.854631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wine</th>\n",
       "      <td>0.044321</td>\n",
       "      <td>1.044655</td>\n",
       "      <td>5.213312</td>\n",
       "      <td>0.044557</td>\n",
       "      <td>6.347845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WordSynonyms</th>\n",
       "      <td>0.361326</td>\n",
       "      <td>23.191680</td>\n",
       "      <td>832.783365</td>\n",
       "      <td>1.926718</td>\n",
       "      <td>858.280105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              cweights_time  fsubsequence_time  tdataset_time  \\\n",
       "dataset_name                                                    \n",
       "Adiac              0.356932           6.251375     867.444809   \n",
       "ArrowHead          0.068162           2.550791      14.467688   \n",
       "BME                0.037609           0.291632       3.115769   \n",
       "Beef               0.141614          36.995622      58.747155   \n",
       "BeetleFly          0.094815          33.239842      16.043617   \n",
       "...                     ...                ...            ...   \n",
       "TwoPatterns        0.093418           0.414763     118.326124   \n",
       "UMD                0.043190           0.443225       5.108370   \n",
       "Wafer              0.082004           0.327180      50.331497   \n",
       "Wine               0.044321           1.044655       5.213312   \n",
       "WordSynonyms       0.361326          23.191680     832.783365   \n",
       "\n",
       "              tclassifier_time        time  \n",
       "dataset_name                                \n",
       "Adiac                 5.253082  879.326493  \n",
       "ArrowHead             0.137025   17.226493  \n",
       "BME                   0.036141    3.482713  \n",
       "Beef                  0.014530   95.910451  \n",
       "BeetleFly             0.007177   49.390765  \n",
       "...                        ...         ...  \n",
       "TwoPatterns           4.722428  123.560247  \n",
       "UMD                   0.119882    5.716431  \n",
       "Wafer                 1.112268   51.854631  \n",
       "Wine                  0.044557    6.347845  \n",
       "WordSynonyms          1.926718  858.280105  \n",
       "\n",
       "[68 rows x 5 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pivot table with the mean of time spent in minutes\n",
    "pivot=pd.pivot_table(df_result_acc, values=['time','cweights_time','fsubsequence_time','tdataset_time','tclassifier_time'], index=['dataset_name'], aggfunc='sum')/60\n",
    "pivot = pivot.reindex(columns=['cweights_time','fsubsequence_time','tdataset_time','tclassifier_time','time'])\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>nb_per_class</th>\n",
       "      <th>half_instance</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>30</th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rpoint</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>half_len</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.311962</td>\n",
       "      <td>2.305446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.801771</td>\n",
       "      <td>6.261969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "nb_per_class  half_instance         1        10  30  50  100  1000  10000\n",
       "rpoint                                                                   \n",
       "half_len                NaN       NaN       NaN NaN NaN  NaN   NaN    NaN\n",
       "1                       NaN       NaN       NaN NaN NaN  NaN   NaN    NaN\n",
       "10                      NaN  0.311962  2.305446 NaN NaN  NaN   NaN    NaN\n",
       "30                      NaN  0.801771  6.261969 NaN NaN  NaN   NaN    NaN\n",
       "50                      NaN       NaN       NaN NaN NaN  NaN   NaN    NaN\n",
       "100                     NaN       NaN       NaN NaN NaN  NaN   NaN    NaN\n",
       "1000                    NaN       NaN       NaN NaN NaN  NaN   NaN    NaN\n",
       "10000                   NaN       NaN       NaN NaN NaN  NaN   NaN    NaN"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pivot table with the mean of time spent in minutes by random points and instances per class\n",
    "pivot = pd.pivot_table(df_result_acc, values='time', index=['rpoint'],columns=['nb_per_class'], aggfunc='mean')/60\n",
    "pivot = pivot.reindex(columns=[\"half_instance\",\"1\",\"10\",\"30\",\"50\",\"100\",\"1000\",\"10000\"], index=[\"half_len\",\"1\",\"10\",\"30\",\"50\",\"100\",\"1000\",\"10000\"])\n",
    "pivot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate weights time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>nb_per_class</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rpoint</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.107884</td>\n",
       "      <td>0.103960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.104333</td>\n",
       "      <td>0.104326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "nb_per_class         1        10\n",
       "rpoint                          \n",
       "10            0.107884  0.103960\n",
       "30            0.104333  0.104326"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df_result_acc, values='cweights_time', index=['rpoint'],columns=['nb_per_class'], aggfunc='mean')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finding subsequences time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>nb_per_class</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rpoint</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.72407</td>\n",
       "      <td>14.828489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.81173</td>\n",
       "      <td>14.916789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "nb_per_class        1         10\n",
       "rpoint                          \n",
       "10            1.72407  14.828489\n",
       "30            1.81173  14.916789"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df_result_acc, values='fsubsequence_time', index=['rpoint'],columns=['nb_per_class'], aggfunc='mean')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform Dataset time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>nb_per_class</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rpoint</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14.348977</td>\n",
       "      <td>120.052097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>42.526258</td>\n",
       "      <td>355.997983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "nb_per_class          1          10\n",
       "rpoint                             \n",
       "10            14.348977  120.052097\n",
       "30            42.526258  355.997983"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df_result_acc, values='tdataset_time', index=['rpoint'],columns=['nb_per_class'], aggfunc='mean')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifier time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>nb_per_class</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rpoint</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.532497</td>\n",
       "      <td>3.337764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.660759</td>\n",
       "      <td>4.690928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "nb_per_class         1        10\n",
       "rpoint                          \n",
       "10            2.532497  3.337764\n",
       "30            3.660759  4.690928"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df_result_acc, values='tclassifier_time', index=['rpoint'],columns=['nb_per_class'], aggfunc='mean')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsast_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "15558ed87e778df9776c3e85b8e1a3f1f5adbf230fcca0229423f99909b60d27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
